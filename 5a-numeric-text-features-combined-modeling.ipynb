{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# ml models decistion tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# One of the Ensemle model -- Random Forset which is ensemple of decision trees\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "# import logistic regression, SVC  for ensembling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# split the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# packages for metric for evalaution of the models\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "from sklearn import metrics\n",
    "# to save the models so that we don't need to train the models every time we need to do prediction\n",
    "from sklearn.externals import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_numeric = pd.read_csv(r'datasets\\1b-crest-after-numeric-preprocessing.csv')\n",
    "df_text = pd.read_csv(r'datasets\\1a-crest-after-text-cleaning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collection', 'document_number', 'release_decision',\n",
       "       'document_page_count', 'sequence_number', 'publication_date',\n",
       "       'content_type', 'collection_labels', 'publication_day',\n",
       "       'publication_month', 'publication_year', 'sub_department',\n",
       "       'sub_department_num', 'check_digit', 'release_decision_num',\n",
       "       'content_type_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>document_number</th>\n",
       "      <th>release_decision</th>\n",
       "      <th>document_page_count</th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>content_type</th>\n",
       "      <th>collection_labels</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>sub_department</th>\n",
       "      <th>sub_department_num</th>\n",
       "      <th>check_digit</th>\n",
       "      <th>release_decision_num</th>\n",
       "      <th>content_type_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General_CIA_Records</td>\n",
       "      <td>CIA-RDP88G01332R001301470016-9</td>\n",
       "      <td>RIPPUB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1986-10-31</td>\n",
       "      <td>MEMO</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1986</td>\n",
       "      <td>RDP</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.064947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General_CIA_Records</td>\n",
       "      <td>CIA-RDP94B00280R001200040002-0</td>\n",
       "      <td>RIPPUB</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1983-06-22</td>\n",
       "      <td>MEMO</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>1983</td>\n",
       "      <td>RDP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.064947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General_CIA_Records</td>\n",
       "      <td>CIA-RDP80-00810A002500690001-1</td>\n",
       "      <td>RIPPUB</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1953-11-03</td>\n",
       "      <td>REPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1953</td>\n",
       "      <td>RDP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.159347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>General_CIA_Records</td>\n",
       "      <td>CIA-RDP82-00457R008500360004-9</td>\n",
       "      <td>RIPPUB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1951-08-13</td>\n",
       "      <td>REPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1951</td>\n",
       "      <td>RDP</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.159347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General_CIA_Records</td>\n",
       "      <td>CIA-RDP70-00211R000100070047-1</td>\n",
       "      <td>RIPPUB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1953-01-05</td>\n",
       "      <td>REPORT</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>RDP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.159347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            collection                 document_number release_decision  \\\n",
       "0  General_CIA_Records  CIA-RDP88G01332R001301470016-9           RIPPUB   \n",
       "1  General_CIA_Records  CIA-RDP94B00280R001200040002-0           RIPPUB   \n",
       "2  General_CIA_Records  CIA-RDP80-00810A002500690001-1           RIPPUB   \n",
       "3  General_CIA_Records  CIA-RDP82-00457R008500360004-9           RIPPUB   \n",
       "4  General_CIA_Records  CIA-RDP70-00211R000100070047-1           RIPPUB   \n",
       "\n",
       "   document_page_count  sequence_number publication_date content_type  \\\n",
       "0                  3.0               16       1986-10-31         MEMO   \n",
       "1                 10.0                2       1983-06-22         MEMO   \n",
       "2                  4.0                1       1953-11-03       REPORT   \n",
       "3                  2.0                4       1951-08-13       REPORT   \n",
       "4                  2.0               47       1953-01-05       REPORT   \n",
       "\n",
       "   collection_labels  publication_day  publication_month  publication_year  \\\n",
       "0                  0               31                 10              1986   \n",
       "1                  0               22                  6              1983   \n",
       "2                  0                3                 11              1953   \n",
       "3                  0               13                  8              1951   \n",
       "4                  0                5                  1              1953   \n",
       "\n",
       "  sub_department  sub_department_num  check_digit  release_decision_num  \\\n",
       "0            RDP                   1            9              0.508693   \n",
       "1            RDP                   1            0              0.508693   \n",
       "2            RDP                   1            1              0.508693   \n",
       "3            RDP                   1            9              0.508693   \n",
       "4            RDP                   1            1              0.508693   \n",
       "\n",
       "   content_type_num  \n",
       "0          0.064947  \n",
       "1          0.064947  \n",
       "2          0.159347  \n",
       "3          0.159347  \n",
       "4          0.159347  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'collection', 'collection_labels', 'title_word_count',\n",
       "       'avg_word_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack the DataFrames on top of each other/ Merge datasets row -wise \n",
    "df1 = df_numeric[['document_page_count', 'sequence_number', 'collection_labels', 'publication_day', 'publication_month', 'publication_year',\n",
    "       'check_digit', 'release_decision_num', 'content_type_num', 'sub_department_num']]\n",
    "\n",
    "df2 = df_text[['title_word_count', 'avg_word_len']]\n",
    "\n",
    "# concat column wise so axis would 1\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'datasets\\5a_CREST_text_and_numeric_features.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document_page_count', 'sequence_number', 'collection_labels',\n",
       "       'publication_day', 'publication_month', 'publication_year',\n",
       "       'check_digit', 'release_decision_num', 'content_type_num',\n",
       "       'sub_department_num', 'title_word_count', 'avg_word_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_page_count</th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>collection_labels</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>check_digit</th>\n",
       "      <th>release_decision_num</th>\n",
       "      <th>content_type_num</th>\n",
       "      <th>sub_department_num</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>6.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1982</td>\n",
       "      <td>9</td>\n",
       "      <td>0.059973</td>\n",
       "      <td>0.159347</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>3.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.057867</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>6.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>44.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1976</td>\n",
       "      <td>2</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.089453</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>6.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_page_count  sequence_number  collection_labels  \\\n",
       "74995                  3.0               13                  4   \n",
       "74996                 22.0                1                  4   \n",
       "74997                  4.0                9                  4   \n",
       "74998                  3.0               66                  4   \n",
       "74999                 44.0               10                  4   \n",
       "\n",
       "       publication_day  publication_month  publication_year  check_digit  \\\n",
       "74995               26                 10              1993            1   \n",
       "74996                5                  1              1982            9   \n",
       "74997                3                 12              1993            1   \n",
       "74998               31                 10              1974            6   \n",
       "74999                4                 10              1976            2   \n",
       "\n",
       "       release_decision_num  content_type_num  sub_department_num  \\\n",
       "74995              0.508693          0.009067                   1   \n",
       "74996              0.059973          0.159347                   1   \n",
       "74997              0.508693          0.020000                   1   \n",
       "74998              0.019733          0.057867                   0   \n",
       "74999              0.508693          0.089453                   1   \n",
       "\n",
       "       title_word_count  avg_word_len  \n",
       "74995                29      6.413793  \n",
       "74996                28      8.000000  \n",
       "74997                19      6.631579  \n",
       "74998                42      6.357143  \n",
       "74999                32      6.937500  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # use resample method from scikit-learn\n",
    "    from sklearn.utils import resample\n",
    "   \n",
    "df_for_production = resample(df, replace=True,    # sample with replacement\n",
    "                                 n_samples=5,     # to match number of values in each class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "df_for_production.to_csv(r'datasets\\CREST_5_samples_for_production.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[['document_page_count', 'sequence_number', 'publication_day', 'publication_month', 'publication_year',\n",
    "       'check_digit', 'release_decision_num', 'content_type_num',\n",
    "       'sub_department_num', 'title_word_count', 'avg_word_len']]\n",
    "\n",
    "y = df[['collection_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_page_count</th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>check_digit</th>\n",
       "      <th>release_decision_num</th>\n",
       "      <th>content_type_num</th>\n",
       "      <th>sub_department_num</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1986</td>\n",
       "      <td>9</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.064947</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>6.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>1983</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508693</td>\n",
       "      <td>0.064947</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_page_count  sequence_number  publication_day  publication_month  \\\n",
       "0                  3.0               16               31                 10   \n",
       "1                 10.0                2               22                  6   \n",
       "\n",
       "   publication_year  check_digit  release_decision_num  content_type_num  \\\n",
       "0              1986            9              0.508693          0.064947   \n",
       "1              1983            0              0.508693          0.064947   \n",
       "\n",
       "   sub_department_num  title_word_count  avg_word_len  \n",
       "0                   1                46      6.434783  \n",
       "1                   1                23      8.782609  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_labels\n",
       "0                  0\n",
       "1                  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.2 , random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try how ensemling ( Random forest wit 10 decision trees ) performs \n",
    "random_forest = RandomForestClassifier(n_estimators=10)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the  random model\n",
    "filepath = r'saved-models-joblib\\trained-text-and-numeric-features\\random_forest_model'\n",
    "joblib.dump(random_forest ,filepath )\n",
    "# load model for prediction\n",
    "random_forest = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random Forest Accuracy = \n",
      "0.9695333333333334\n",
      "\n",
      "\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      General_CIA_Records       0.93      0.93      0.93      2995\n",
      "              NGA_Records       0.94      0.95      0.94      2984\n",
      "     Scientific_Abstracts       1.00      1.00      1.00      3011\n",
      "Consolidated_Translations       1.00      1.00      1.00      2990\n",
      "                     Misc       0.98      0.97      0.98      3020\n",
      "\n",
      "                micro avg       0.97      0.97      0.97     15000\n",
      "                macro avg       0.97      0.97      0.97     15000\n",
      "             weighted avg       0.97      0.97      0.97     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Random Forest Accuracy = \")\n",
    "print(random_forest.score(X_test, y_test))\n",
    "print(\"\\n\")\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=df_numeric['collection'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py:621: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.5, n_estimators=20, n_jobs=None, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest is performing better than Decision tree.Ensemling improved precision and F1-score.\n",
    "# let's try bagging classifier\n",
    "# We will give 20 Decisions Trees, each with 50% of training dataset and 100% features\n",
    "bg = BaggingClassifier( DecisionTreeClassifier() , max_samples = 0.5 , max_features= 1.0 , n_estimators=20 )\n",
    "bg.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the baggign classifier model\n",
    "filepath = r'saved-models-joblib\\trained-text-and-numeric-features\\BaggingClassifier_model'\n",
    "joblib.dump(bg ,filepath )\n",
    "# load model for prediction\n",
    "bg = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bagging Classifier Accuracy = \n",
      "0.9712\n",
      "\n",
      "\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      General_CIA_Records       0.94      0.92      0.93      2995\n",
      "              NGA_Records       0.93      0.96      0.95      2984\n",
      "     Scientific_Abstracts       1.00      1.00      1.00      3011\n",
      "Consolidated_Translations       1.00      1.00      1.00      2990\n",
      "                     Misc       0.98      0.98      0.98      3020\n",
      "\n",
      "                micro avg       0.97      0.97      0.97     15000\n",
      "                macro avg       0.97      0.97      0.97     15000\n",
      "             weighted avg       0.97      0.97      0.97     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Bagging Classifier Accuracy = \")\n",
    "print(bg.score(X_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_pred = bg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=df_numeric['collection'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the performance of BoostingClassifier -ADABoost\n",
    "# 10 decision trees , learning rate will shrink the contribution of each individual learner \n",
    "adaboost = AdaBoostClassifier( DecisionTreeClassifier() , n_estimators= 10 , learning_rate= 1 )\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the adaboost classifier model\n",
    "filepath = r'saved-models-joblib\\trained-text-and-numeric-features\\adaboost_model'\n",
    "joblib.dump(adaboost ,filepath )\n",
    "# load model for prediction\n",
    "adaboost = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA Boost model Accuracy = \n",
      "0.9626\n",
      "\n",
      "\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      General_CIA_Records       0.92      0.90      0.91      2995\n",
      "              NGA_Records       0.92      0.93      0.93      2984\n",
      "     Scientific_Abstracts       1.00      1.00      1.00      3011\n",
      "Consolidated_Translations       1.00      1.00      1.00      2990\n",
      "                     Misc       0.97      0.98      0.97      3020\n",
      "\n",
      "                micro avg       0.96      0.96      0.96     15000\n",
      "                macro avg       0.96      0.96      0.96     15000\n",
      "             weighted avg       0.96      0.96      0.96     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ADA Boost model Accuracy = \")\n",
    "print(adaboost.score(X_test , y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "y_pred_adaboost = adaboost.predict(X_test)\n",
    "print(classification_report(y_test , y_pred_adaboost, target_names=df_numeric['collection'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's have our own ensembles method\n",
    "\n",
    "# votoing hard means votes on the labels not on the probabilities\n",
    "ensemble_vc = VotingClassifier( estimators=[ ('adaboost', adaboost) , \n",
    "                                            ('random_forest', random_forest) , \n",
    "                                            ('bg', bg)] , voting='hard' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('adaboost', AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_sa...imators=20, n_jobs=None, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_vc.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the custom ensembling classifier model \n",
    "filepath = r'saved-models-joblib\\trained-text-and-numeric-features\\ensemble_voting_classifier_model'\n",
    "joblib.dump(ensemble_vc ,filepath )\n",
    "# load model for prediction\n",
    "ensemble_vc = joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Voting Classifier Accuracy = \n",
      "0.9733333333333334\n",
      "\n",
      "\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      General_CIA_Records       0.94      0.93      0.94      2995\n",
      "              NGA_Records       0.94      0.96      0.95      2984\n",
      "     Scientific_Abstracts       1.00      1.00      1.00      3011\n",
      "Consolidated_Translations       1.00      1.00      1.00      2990\n",
      "                     Misc       0.98      0.98      0.98      3020\n",
      "\n",
      "                micro avg       0.97      0.97      0.97     15000\n",
      "                macro avg       0.97      0.97      0.97     15000\n",
      "             weighted avg       0.97      0.97      0.97     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom Voting Classifier Accuracy = \")\n",
    "print(ensemble_vc.score(X_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# print the metrices for our ensemmbled model\n",
    "y_pred_ensemble_vc = ensemble_vc.predict(X_test)\n",
    "print( classification_report(y_test , y_pred_ensemble_vc, target_names=df_numeric['collection'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
